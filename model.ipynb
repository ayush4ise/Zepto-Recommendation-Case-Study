{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove consecutive duplicates from list\n",
    "def remove_consec_duplicates(raw_lst):\n",
    "  previous_value = None\n",
    "  new_lst = []\n",
    "\n",
    "  for elem in raw_lst:\n",
    "    if elem != previous_value:\n",
    "        new_lst.append(elem)\n",
    "        previous_value = elem\n",
    "        \n",
    "  return new_lst\n",
    "\n",
    "# generate sequential products\n",
    "def generate_sequential_products(data):\n",
    "  import pandas as pd\n",
    "  from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "  data_modified = data.copy()\n",
    "  # Label encode the product names\n",
    "  encoder = LabelEncoder()\n",
    "  data_modified['product_id'] = encoder.fit_transform(data_modified['product_name'])\n",
    "\n",
    "  # Remove sessions where only a single product is viewed\n",
    "  data_modified = data_modified.groupby(\"session_id\").filter(lambda x: len(x) > 1)\n",
    "  # Group product view sequences by session id\n",
    "  data_modified = data_modified.groupby(\"session_id\")[\"product_id\"].apply(list)\n",
    "  # Remove consecutive duplicate product views from the sequences genereated in the previous step\n",
    "  data_modified = data_modified.apply(remove_consec_duplicates)\n",
    "\n",
    "  #Convert series to data frame and reset index\n",
    "  data_modified = data_modified.to_frame().reset_index().rename(columns={\"product_id\": \"chronological_product_sequence\"})\n",
    "\n",
    "  return data_modified, encoder\n",
    "\n",
    "# create product embeddings using word2vec\n",
    "def create_product_embeddings(data_modified):\n",
    "  import gensim\n",
    "  from gensim.models import Word2Vec\n",
    "  import pandas as pd\n",
    "\n",
    "  # Convert the product sequences to list of lists\n",
    "  session_based_product_sequences = data_modified.copy()\n",
    "  \n",
    "  # Create Gensim CBOW model\n",
    "  session_product_sequences = session_based_product_sequences['chronological_product_sequence'].apply(list)\n",
    "  word2vec_model = gensim.models.Word2Vec(session_product_sequences, min_count = 1, vector_size = 10, window = 5)\n",
    "  \n",
    "  # numpy.ndarrays of product vectors\n",
    "  product_vectors = word2vec_model.wv.vectors\n",
    "\n",
    "  # productID_list = word2vec_model.wv.vocab.keys()\n",
    "  productID_list = word2vec_model.wv.index_to_key\n",
    "  vector_list = word2vec_model.wv.vectors.tolist()\n",
    "  data_tuples = list(zip(productID_list,vector_list))\n",
    "  product_ids_and_vectors = pd.DataFrame(data_tuples, columns=['Product_ID','Vectors'])\n",
    "\n",
    "  return product_ids_and_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the cluster distribution\n",
    "def plot_cluster_distribution(kmeans_model):\n",
    "  import matplotlib.pyplot as plt\n",
    "  import numpy as np\n",
    "\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  plt.hist(kmeans_model.labels_, bins=np.arange(kmeans_model.n_clusters + 1) - 0.5, rwidth=0.7, color='skyblue', edgecolor='black')\n",
    "  plt.xticks(np.arange(kmeans_model.n_clusters))\n",
    "  plt.ylabel(\"Number of Products\", fontsize=14)\n",
    "  plt.xlabel(\"Cluster No\", fontsize=14)\n",
    "  plt.title(\"Cluster Distribution\", fontsize=18, fontweight='bold')\n",
    "  plt.grid(axis='y', linestyle='--', linewidth=0.7)\n",
    "  plt.tight_layout()\n",
    "  plt.savefig('cluster_distribution.png')\n",
    "\n",
    "  # Hide the plot\n",
    "  plt.close()\n",
    "\n",
    "# Plotting the cluster scatter\n",
    "def plot_cluster_scatter(product_vectors):\n",
    "  import matplotlib.pyplot as plt\n",
    "  from sklearn.decomposition import PCA\n",
    "  from sklearn.cluster import KMeans\n",
    "  import numpy as np\n",
    "\n",
    "  pca = PCA(n_components=2)\n",
    "  two_dimensions_vectors = pca.fit_transform(product_vectors)\n",
    "\n",
    "  kmeans_model = KMeans(n_clusters=10, random_state=0).fit(two_dimensions_vectors)\n",
    "  labels = kmeans_model.labels_\n",
    "\n",
    "  # Getting the Centroids\n",
    "  centroids = kmeans_model.cluster_centers_\n",
    "  unique_labels = np.unique(labels)\n",
    "\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  \n",
    "  # Plotting the results\n",
    "  for label in unique_labels:\n",
    "      plt.scatter(two_dimensions_vectors[labels == label, 0], \n",
    "                  two_dimensions_vectors[labels == label, 1], \n",
    "                  label=f'Cluster {label}', s=50, alpha=0.6)\n",
    "\n",
    "  plt.scatter(centroids[:, 0], centroids[:, 1], s=200, color='black', marker='X', label='Centroids')\n",
    "\n",
    "  plt.xlabel('PCA Component 1', fontsize=14)\n",
    "  plt.ylabel('PCA Component 2', fontsize=14)\n",
    "  plt.title(\"Cluster Scatter\", fontsize=18, fontweight='bold')\n",
    "  plt.legend(loc='best', fontsize=12)\n",
    "  plt.grid(True, linestyle='--', linewidth=0.7)\n",
    "  plt.tight_layout()\n",
    "  plt.savefig('cluster_scatter.png')\n",
    "\n",
    "  # Hide the plot\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering model\n",
    "def fit_kmeans(product_ids_and_vectors):\n",
    "  import gensim\n",
    "  from gensim.models import Word2Vec\n",
    "  from sklearn.cluster import KMeans\n",
    "  import matplotlib.pyplot as plt\n",
    "  import numpy as np\n",
    "  \n",
    "  product_ids_and_vectors_train = product_ids_and_vectors.copy()\n",
    "\n",
    "  # Get product vectors from Word2Vec\n",
    "  array_product_vectors = np.array(product_ids_and_vectors_train[\"Vectors\"].values.tolist())\n",
    "\n",
    "  # Fit K-Means algorithm on those embeddings\n",
    "  kmeans_model = KMeans(n_clusters=10, random_state=0).fit(array_product_vectors)\n",
    "\n",
    "  # Cluster Distribution Plot\n",
    "  plot_cluster_distribution(kmeans_model)\n",
    "\n",
    "  # Cluster Scatter Plot\n",
    "  plot_cluster_scatter(array_product_vectors)\n",
    "  \n",
    "  return kmeans_model\n",
    "\n",
    "# Final product clusters\n",
    "def save_final_product_clusters(clustering_model, product_ids_and_vectors):\n",
    "  import numpy as np\n",
    "\n",
    "  model = clustering_model\n",
    "  \n",
    "  product_ids_and_vectors_modified = product_ids_and_vectors.copy()\n",
    "  array_product_vectors = np.array(product_ids_and_vectors_modified[\"Vectors\"].values.tolist())\n",
    "\n",
    "  assigned_cluster_no = model.fit_predict(array_product_vectors).tolist()\n",
    "\n",
    "  product_ids_and_vectors_modified[\"Cluster_No\"] = assigned_cluster_no\n",
    "  cluster_members_df = product_ids_and_vectors_modified[[\"Product_ID\",\"Cluster_No\"]].groupby(\"Cluster_No\")['Product_ID'].apply(list).to_frame().reset_index().rename(columns={'Product_ID': 'Cluster_Member_List'})\n",
    "\n",
    "\n",
    "  return cluster_members_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ed966131fcb96e0efc4ff2b716a3e</td>\n",
       "      <td>beetroot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000ed966131fcb96e0efc4ff2b716a3e</td>\n",
       "      <td>cucumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013eab657eaf2d82d7f1e13023d95c2</td>\n",
       "      <td>onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0013eab657eaf2d82d7f1e13023d95c2</td>\n",
       "      <td>long shelf life milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0013fabde1e543dd541be925266aadbc</td>\n",
       "      <td>dates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         session_id          product_name\n",
       "0  000ed966131fcb96e0efc4ff2b716a3e              beetroot\n",
       "1  000ed966131fcb96e0efc4ff2b716a3e              cucumber\n",
       "2  0013eab657eaf2d82d7f1e13023d95c2                 onion\n",
       "3  0013eab657eaf2d82d7f1e13023d95c2  long shelf life milk\n",
       "4  0013fabde1e543dd541be925266aadbc                 dates"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv('data/session_data.csv')\n",
    "\n",
    "# Display the first few rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sequential products\n",
    "data, encoder = generate_sequential_products(data)\n",
    "\n",
    "# Create product embeddings\n",
    "product_ids_and_vectors = create_product_embeddings(data)\n",
    "\n",
    "# Fit KMeans clustering model\n",
    "clustering_model = fit_kmeans(product_ids_and_vectors)\n",
    "\n",
    "# Save final product clusters\n",
    "final_product_clusters = save_final_product_clusters(clustering_model, product_ids_and_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Similar Product Recommendations for notebook:  ['notebook' 'colours' 'sharpener' 'craft paper' 'pencil']\n"
     ]
    }
   ],
   "source": [
    "# Product ID to generate recommendations\n",
    "product_id = 260 # notebook\n",
    "# Get product name from product ID\n",
    "product_name = encoder.inverse_transform([product_id])[0]\n",
    "\n",
    "# Get Vector (Embedding) array of the given product\n",
    "vector_array = np.array(product_ids_and_vectors[product_ids_and_vectors[\"Product_ID\"]==product_id][\"Vectors\"].tolist())\n",
    "\n",
    "# Get cluster number for the given product assigned by the model\n",
    "cluster_no = clustering_model.predict(vector_array)[0]\n",
    "\n",
    "# Get members list of the cluster that the given product is assigned to \n",
    "cluster_members_list = final_product_clusters[final_product_clusters['Cluster_No']==cluster_no]['Cluster_Member_List'].iloc[0]\n",
    "\n",
    "# Randomly select 5 product recommendations from the cluster members excluding the given product\n",
    "from random import sample\n",
    "# cluster_members_list.remove(product_id)\n",
    "five_product_recommendations = sample(cluster_members_list, 5)\n",
    "\n",
    "# Map the recommended product IDs to product names in initial data\n",
    "five_product_recommendations = encoder.inverse_transform(five_product_recommendations)\n",
    "\n",
    "\n",
    "print(\"5 Similar Product Recommendations for {}: \".format(product_name),five_product_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Silhouette Score:  0.21531029411878816\n",
      "Test Silhouette Score:  0.3921875518440196\n"
     ]
    }
   ],
   "source": [
    "# train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the data\n",
    "data = pd.read_csv('data/session_data.csv')\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=0)\n",
    "\n",
    "# Generate sequential products\n",
    "train_data, encoder = generate_sequential_products(train_data)\n",
    "test_data, encoder = generate_sequential_products(test_data)\n",
    "\n",
    "# Create product embeddings\n",
    "train_product_ids_and_vectors = create_product_embeddings(train_data)\n",
    "test_product_ids_and_vectors = create_product_embeddings(test_data)\n",
    "\n",
    "# Fit KMeans clustering model\n",
    "clustering_model = fit_kmeans(train_product_ids_and_vectors)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Get product vectors from Word2Vec\n",
    "array_train_product_vectors = np.array(train_product_ids_and_vectors[\"Vectors\"].values.tolist())\n",
    "array_test_product_vectors = np.array(test_product_ids_and_vectors[\"Vectors\"].values.tolist())\n",
    "\n",
    "# Get cluster number for the given product assigned by the model\n",
    "train_assigned_cluster_no = clustering_model.predict(array_train_product_vectors)\n",
    "test_assigned_cluster_no = clustering_model.predict(array_test_product_vectors)\n",
    "\n",
    "# Calculate silhouette score\n",
    "train_silhouette_score = silhouette_score(array_train_product_vectors, train_assigned_cluster_no)\n",
    "test_silhouette_score = silhouette_score(array_test_product_vectors, test_assigned_cluster_no)\n",
    "\n",
    "print(\"Train Silhouette Score: \", train_silhouette_score)\n",
    "print(\"Test Silhouette Score: \", test_silhouette_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
